n_layers: 4
n_heads: 2
hidden_size: 256
attribute_hidden_size: [64]
inner_size: 256
hidden_dropout_prob: 0.5
attn_dropout_prob: 0.3
hidden_act: 'gelu'
layer_norm_eps: 1e-12
initializer_range: 0.02
selected_features: ['class']
pooling_mode: 'sum'
loss_type: 'CE'
weight_sharing: 'not'
fusion_type: 'concat'
lamdas: [10]
text_field: 'title'
text_fusion: 'sum'
vis: 0
pos_atten: 1
gpt_text: ""
text_print: 0
